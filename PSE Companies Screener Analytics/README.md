# PSE Companies Screener Analytics

## 1. Introduction

### Overview
This project involved creating an analytics solution to scrape public companies' balance sheets and financial statements from edge.pse.com.ph, transform the data, and visualize it in Power BI for investment analysis. The goal was to enable investors to compare financial metrics across companies efficiently.

### Key Objectives
- Scrape financial data (e.g., balance sheets, income statements) from public company websites.
- Clean and standardize the data for analysis.
- Develop interactive Power BI dashboards to compare financial metrics.

### Technologies and Tools
- **Python**: For web scraping and data transformation.
- **BeautifulSoup**: For scraping financial data from websites.
- **Pandas**: For data cleaning and manipulation.
- **Power BI**: For data visualization and dashboard creation.

---

## 2. Problem Statement

### Challenge
I needed a reliable way to access and compare financial data from multiple public companies. Manual data collection was:
- **Time-Consuming**: Hours spent gathering data from multiple sources.
- **Error-Prone**: Inconsistencies in data formats and manual entry errors.
- **Limited Insights**: Lack of a centralized platform to compare financial metrics.

Automating data collection and providing a centralized analytics platform was essential to enable faster, data-driven investment decisions and improve accuracy.

---

## 3. Design Process

### Steps Taken
1. **Data Collection**: Identified target websites and financial data to scrape.
2. **Web Scraping**: Developed Python scripts using BeautifulSoup to extract financial data.
3. **Data Transformation**: Cleaned and standardized data using Pandas (e.g., handling missing values, converting currencies).
4. **Data Storage**: Stored scraped data in CSV file for further processing.
5. **Dashboard Design**: Created interactive Power BI dashboards to visualize key financial metrics.

### Tools and Methodologies
- **Web Scraping**: Automated data extraction from websites.
- **ETL Processes**: Extracted, transformed, and loaded data into a structured format.
- **Data Visualization**: Designed interactive dashboards in Power BI for easy comparison.

---

## 4. Implementation

### Development and Deployment
- Developed Python scripts to scrape financial data from public company websites.
- Cleaned and transformed the data to ensure consistency (e.g., standardizing date formats, calculating financial ratios).
- Loaded the data into Power BI and created interactive dashboards.
- Deployed the solution on a shared Power BI workspace for stakeholders to access.

### Key Features
- **Automated Scraping**: Scheduled Python scripts to scrape data daily.
- **Interactive Dashboards**: Power BI dashboards with filters for company, industry, and time period.
- **Financial Metrics**: Visualizations for key metrics like revenue, net income, debt-to-equity ratio, and P/E ratio.

---

## 5. Results

### Outcomes and Benefits
- **Time Savings**: Reduced data collection time from hours to minutes.
- **Improved Accuracy**: Eliminated manual errors in data entry.

### Metrics Impacted
- **Data Collection Time**: Virtually reduced all time required to collect data.
- **Investment Decision Speed**: Financial metrics are easily compared and filtered for better investment decisions.

---

## 6. Lessons Learned

### Key Takeaways
- Web scraping requires robust error handling to handle dynamic website changes.
- Automation significantly improves efficiency and accuracy in data-driven processes.

### Areas for Improvement
- Add predictive analytics features for forecasting financial performance.

### Skills Gained
- Proficiency in web scraping with Python (BeautifulSoup).
- Advanced data transformation and cleaning techniques using Pandas.
- Experience in designing interactive dashboards in Power BI.
